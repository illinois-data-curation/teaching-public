{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Data Cleaning with the Relational Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we apply the relational model for data cleaning using DuckDB. This exercise assumes that you have repaired the following data errors in the example City of Chicago Food Inspection data using a tool such as OpenRefine:\n",
    "* License numbers are all numeric values\n",
    "* Inspection dates are all valid dates in a consistent format\n",
    "* City, State, and Zip have been parsed into separate fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "\n",
    "* Apply strategies for data cleaning using the relational model including implementing a relational schema, integrity constarints, and queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "* Install `pandas` and `duckdb` Python libraries\n",
    "* **Optional**:  Install the [DuckDB command line interface](https://duckdb.org/docs/installation/?version=stable&environment=cli) to use `duckdb` from the terminal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Data\n",
    "\n",
    "The cleaned data is in `datasets/inspections/food-inspections-dirty.csv`. We can use the DuckDB Python API to query the CSV data directly and return a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\"SELECT * FROM '../datasets/inspections/food-inspections-dirty.csv' limit 5\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Schema\n",
    "\n",
    "The next step is to create a relational schema that can be used to import the dataset.\n",
    "\n",
    "* Create a file named `schema.sql` that will be used to create a database.\n",
    "* The file must define the schema for a table named `INSPECTIONS` that will store the inspections data. \n",
    "* The table should have a primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect(\"inspections.db\") as con:\n",
    "    with open(\"schema.sql\", \"r\") as f:\n",
    "        # Create the DB schema\n",
    "        con.sql(f.read())\n",
    "        # Import data\n",
    "        con.sql(\"INSERT INTO inspections (SELECT * FROM read_csv('../datasets/inspections/food-inspections-cleaned.csv'))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "* What are the column names and datatypes?\n",
    "* What can we use for the primary key?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the data\n",
    "\n",
    "Define a query that can be used to count the number of rows in the `INSPECTIONS` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"\"\"\n",
    "    SELECT COUNT(*) AS COUNT from INSPECTIONS\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "with duckdb.connect(\"inspections.db\") as con:\n",
    "    count = con.sql(q1).fetchone()[0]\n",
    "    assert(count == 720)\n",
    "    print(\"Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the contents of the `Violations` column. Note that the column contains multiple nested records delimited with pipe (`|`). \n",
    "\n",
    "\n",
    "According to the first normal form, columns should not contain nested values. So our next step is to normalize the violations data. But first, we need to understand what each record contains.  Use the DuckDB `regexp_split_to_table()` operation to split each violation into a separate row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = \"\"\"\n",
    "   SELECT inspection_id, regexp_split_to_table(Violations, '\\\\|') \n",
    "   FROM INSPECTIONS\n",
    "   LIMIT 10\n",
    "\"\"\"\n",
    "with duckdb.connect(\"inspections.db\") as con:\n",
    "    df = con.sql(q3).df()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the violations have a consistent format:\n",
    "\n",
    "```\n",
    "(30). (FOOD IN ORIGINAL CONTAINER, PROPERLY LABELED: CUSTOMER ADVISORY POSTED AS NEEDED) - Comments: (LABEL ALL BULK CONTAINERS IN PREP AREA)\n",
    "```\n",
    "\n",
    "The violations refer to a list of standard codes and descriptions found on the [Food Inspection Report Form](https://www.chicago.gov/dam/city/depts/cdph/food_env/general/Food_Protection/Blankinspectionreport.pdf) and consist of:\n",
    "1. A numeric violation code or identifier\n",
    "2. A standard description of the violation\n",
    "3. An optional comment from the inspector at the time of inspection\n",
    "\n",
    "The next step is to create the new table(s) and use SQL or Python to parse and transform the source data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**\n",
    "* What should the new table(s) be?\n",
    "* How should we handle duplicated data such as the violation code and description?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the Data\n",
    "\n",
    "Update your `schema.sql` to create additional table(s) to store the violations data:\n",
    "* `VIOLATIONS`: Table to store unique information about violations. It should have a primary key that serves as a foreign key for the `INSPECTION_VIOLATIONS` table.\n",
    "* `INSPECTION_VIOLATIONS`: Table to store **unique** information about violations associated with each inspection. It should have a primary key and foreign keys to `INSPECTIONS` and `VIOLATIONS`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to write a query that can parse the `Violations` column into its separate parts:\n",
    "* For each inspection, use `regexp_split_to_table` to split the violations records by the `|` delimiter\n",
    "* For each violation record, use `regexp_extract` to extract the individual parts (violation code, description, and comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4 = \"\"\"\n",
    "    select inspection_id, regexp_extract(\n",
    "        trim(regexp_split_to_table(inspections.violations, '\\\\|')),\n",
    "        '^(\\\\d+)\\\\.(.*?)(?:-\\\\s+Comments?:(.*))?$',\n",
    "        ['violation_id', 'description', 'comments'], 's'\n",
    "    ) as violation\n",
    "    from inspections\n",
    "\"\"\"\n",
    "\n",
    "with duckdb.connect(\"inspections.db\") as con:\n",
    "    df = con.sql(q4).df()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This rather complex query uses DuckDB's [text functions](https://duckdb.org/docs/sql/functions/char.html) to parse the column:\n",
    "* `regexp_split_to_table` splits the delimited string into new rows\n",
    "* `regexp_extract` uses regular expression capture groups to match parse of the violation string\n",
    "\n",
    "The regular expression consists of:\n",
    "* `^(\\d+)\\.`: The first capture group starts at the beginning of the line (`^`) and consists of one or more numeric digits (`\\d+`) followed by a literal period (`\\.`)\n",
    "* `(.*?)`: The second capture group consists of everything between the period and an optional `- Comments:` block\n",
    "* `(?:-\\s+Comments?:(.*))?$'`: The third capture group `(?:...)?` is actually an optional `(...)?` non-capturing group `(?:...)`. This says that `- Comments: ` part is optional, since some violations do not contain a comment.\n",
    "* `(.*)`: The fourth capture group `(.*)` consists of everything between the `- Comments:` and the end of the line `$`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`regexp_extract` returns a JSON structure that can now be referenced in queries:\n",
    "\n",
    "```\n",
    "{'violation_id': '', 'description': '', 'comments': ''}\n",
    "```\n",
    "\n",
    "Note that the `s` option to `regexp_extract` specifies that matches are not [newline sensitive](https://duckdb.org/docs/sql/functions/regular_expressions.html#options-for-regular-expression-functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5 = \"\"\"\n",
    "    select inspection_id, violation['violation_id'] as violation_id, trim(violation['description']) as description\n",
    "    from\n",
    "    (\n",
    "        select inspection_id, regexp_extract(\n",
    "            trim(regexp_split_to_table(inspections.violations, '\\\\|')),\n",
    "            '^(\\\\d+)\\\\.(.*?)(?:-\\\\s+Comments?:(.*))?$',\n",
    "            ['violation_id', 'description', 'comments'], 's'\n",
    "        ) as violation\n",
    "        from inspections\n",
    "    ) as inspections\n",
    "\"\"\"\n",
    "with duckdb.connect(\"inspections.db\") as con:\n",
    "    df = con.sql(q5).df()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the violations codes and descriptions are indeed duplicated. The next step is to determine whether they are truly unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5 = \"\"\"\n",
    "    select distinct violation['violation_id'] as violation_id, trim(violation['description']) as description\n",
    "    from\n",
    "    (\n",
    "        select regexp_extract(\n",
    "            trim(regexp_split_to_table(inspections.violations, '\\\\|')),\n",
    "            '^(\\\\d+)\\\\.(.*?)(?:-\\\\s+Comments?:(.*))?$',\n",
    "            ['violation_id', 'description', 'comments'], 's'\n",
    "        ) as violation\n",
    "        from inspections\n",
    "    ) as inspections\n",
    "    order by cast(violation_id as integer);\n",
    "\"\"\"\n",
    "with duckdb.connect(\"inspections.db\") as con:\n",
    "    df = con.sql(q5).df()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we're ready to populate the new `VIOLATIONS` table. If the `violation_id` is specified as the primary key, we will see if these are truly unique codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q6 = \"\"\"\n",
    "    insert into violations\n",
    "    select distinct violation['violation_id'] as violation_id, trim(violation['description']) as description\n",
    "    from\n",
    "    (\n",
    "        select regexp_extract(\n",
    "            trim(regexp_split_to_table(inspections.violations, '\\\\|')),\n",
    "            '^(\\\\d+)\\\\.(.*?)(?:-\\\\s+Comments?:(.*))?$',\n",
    "            ['violation_id', 'description', 'comments'], 's'\n",
    "        ) as violation\n",
    "        from inspections\n",
    "    ) as inspections\n",
    "    order by cast(violation_id as integer);\n",
    "\"\"\"\n",
    "with duckdb.connect(\"inspections.db\") as con:\n",
    "    con.sql(q6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect(\"inspections.db\") as con:\n",
    "    df = con.sql(\"SELECT * FROM VIOLATIONS\").df()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to populate the `INSPECTIONS_VIOLATIONS` table. This should be easy now, since we already have the query to parse the violations data.\n",
    "\n",
    "The table should contain the `INSPECTION_ID` referencing the INSPECTIONS table, `VIOLATION_ID` referencing the `VIOLATIONS` table, and inspection-specific `COMMENT`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q7 = \"\"\"\n",
    "    insert into inspection_violations\n",
    "    select inspection_id, violation['violation_id'] as violation_id, trim(violation['comments']) as comment\n",
    "    from\n",
    "    (\n",
    "        select DISTINCT inspection_id, regexp_extract(\n",
    "            trim(regexp_split_to_table(inspections.violations, '\\\\|')),\n",
    "            '^(\\\\d+)\\\\.(.*?)(?:-\\\\s+Comments?:\\\\s+(.*))?$',\n",
    "            ['violation_id', 'description', 'comments'], 's'\n",
    "        ) as violation\n",
    "        from inspections \n",
    "    ) \n",
    "    order by inspection_id, cast(violation_id as integer);\n",
    "\"\"\"\n",
    "with duckdb.connect(\"inspections.db\") as con:\n",
    "    con.sql(q7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect(\"inspections.db\") as con:\n",
    "    df = con.sql(\"SELECT * FROM INSPECTION_VIOLATIONS\").df()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrity Constraints\n",
    "\n",
    "We can use our knowledge of the domain to define integrity constraints that can be used to further identify errors in the data.  In fact, we have already defined constaints.  For example, specifing the `violation_id` as the primary key on the violations table indicates that $ViolationID -> Violation Description$. If this constraint had been violated, our inserts into the table would have failed.\n",
    "\n",
    "Below we use SQL queries to identify potential errors based on several functional dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zip -> City, State\n",
    "\n",
    "Based on our knowledge of US ZIP Codes, we expect that, across all inspection records, the ZIP Code will determine the City and State. We can confirm this with the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = \"\"\"\n",
    "    SELECT i1.zip, i1.city, i2.city, i1.state, i2.state \n",
    "    FROM inspections i1, inspections i2\n",
    "    WHERE i1.zip = i2.zip\n",
    "    AND (i1.city != i2.city or i1.state != i2.state)\n",
    "\"\"\"\n",
    "with duckdb.connect(\"inspections.db\") as con:\n",
    "    df = con.sql(c1).df()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query returns rows where the ZIP Code matches between records but the city or state does not.  We see a few instances of case differences, which could be corrected by consistently using upper or lower case.  We also see what appeare to be typos in the data that should be corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBAName -> Zip\n",
    "\n",
    "We also expect that a given business name should determine its location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = \"\"\"\n",
    "    SELECT i1.DBA_Name, i1.zip, i2.zip \n",
    "    FROM inspections i1, inspections i2\n",
    "    WHERE i1.DBA_Name = i2.DBA_Name\n",
    "    AND i1.zip != i2.zip\n",
    "\"\"\"\n",
    "with duckdb.connect(\"inspections.db\") as con:\n",
    "    df = con.sql(c2).df()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see several potential issues here, but the cause is unclear. Perhaps a restaurant moved between inspection dates? Perhaps food trucks are inspected at different locations? Let's include the inspection date and address:\n",
    "\n",
    "(Perhaps DBAName, Inspection Date -> Zip?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = \"\"\"\n",
    "    SELECT i1.DBA_Name, i1.inspection_date, i2.inspection_date, i1.address, i1.address, i1.zip, i2.zip \n",
    "    FROM inspections i1, inspections i2\n",
    "    WHERE i1.DBA_Name = i2.DBA_Name\n",
    "    AND i1.zip != i2.zip\n",
    "\"\"\"\n",
    "with duckdb.connect(\"inspections.db\") as con:\n",
    "    df = con.sql(c3).df()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the addresses are the same but the ZIP Codes differ, suggesting an error in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The relational model is a powerful tool for data cleaning.\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
